{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### _Causal inference beyond the potential outcome framework_\n",
    "# Pearl's graphical theory of causality\n",
    "\n",
    "---\n",
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/ce/Huberlin-logo.svg\" width=\"200\" align=\"right\"/>\n",
    "</div>\n",
    "\n",
    "Information Systems Seminar @ HU Berlin\n",
    "\n",
    "Gerome Wolf, Gleb Zhidkov, Nesrin Othmann, and Mariia Semenenko\n",
    "\n",
    "28.01.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Causality $\\neq$ correlation and prediction\n",
    "![meme](correlation_IS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objective of causal inference\n",
    "\n",
    "- Identify and estimate causal effect\n",
    "- confounder-free point estimates capturing the difference in outcomes between treated and non-treated observations that is solely attributable to a specific intervention\n",
    "\n",
    "\n",
    "- observational vs. experimental data\n",
    "- typical sources of confoundingness / \"endogeneity\"\n",
    "\n",
    "    1. Omitted variable $\\rightarrow$ OVB, remedy: include proxy variable\n",
    "    \n",
    "    2. Measurement error in independent variable $\\rightarrow$ attenuation bias, remedy: structural model\n",
    "    \n",
    "    3. Simultaneity (regressors correlated with structural error term of dependent variable)\n",
    "        - price and quantity are determined simultaneously in equilibrium through demand and supply\n",
    "        - more unknowns than equations, impossible to identify causal effect of price on quantity within this system\n",
    "\n",
    "\n",
    "- popular techniques\n",
    "\n",
    "    1. Linear regression\n",
    "    2. Propensity score matching\n",
    "    3. Instrumental variables\n",
    "    4. Difference-in-differences\n",
    "    5. Regression discontinuity design\n",
    "    6. Structural vectorautoregressive models for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Potential outcome framework & \"counterfactual\"\n",
    "\n",
    "- What is the causal effect of hospitalization?\n",
    "\n",
    "    - naively comparing group means yields that people who went to hospital were, on average, less healthy than others who did not go to hospital <br>$\\rightarrow$ don't go to hospital!\n",
    "    - self-selection!\n",
    "\n",
    "Recall the potential outcome framework of Neyman-Rubin (1923, 1974) and Rosenbaum (1983):\n",
    "\n",
    "The observed outcome, $Y_i$, can be written in terms of potential  outcomes as\n",
    "\n",
    "\\begin{align*}\n",
    "    Y_i &=\n",
    "    \\begin{cases}\n",
    "        Y_{1i},& \\text{if } D_i = 1\\\\\n",
    "        Y_{0i}, & \\text{if } D_i = 0\\\\\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    &= Y_{0i} + (Y_{1i} - Y_{0i}) D_i\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\mathop{\\mathbb{E}}[Y_{i}|D_i = 1] - \\mathop{\\mathbb{E}}[Y_{i}|D_i = 0]}_\\text{Observable difference in mean outcomes} = \\underbrace{\\mathop{\\mathbb{E}}[Y_{1i}|D_i = 1] - \\color{red}{\\mathop{\\mathbb{E}}[Y_{0i}|D_i = 1]}}_\\text{Average treatment effect on the treated} + \\underbrace{\\mathop{\\mathbb{E}}[Y_{0i}|D_i = 1] - \\mathop{\\mathbb{E}}[Y_{0i}|D_i = 0]}_\\text{Selection bias}\n",
    "\\end{align*}\n",
    "\n",
    "<table><tr><td><img src=https://efresh.com/sites/default/files/Green-Apple_1.jpg width=\"100\"></td><td><img src=http://sod.com.bd/wp-content/uploads/2020/04/Apple.jpg width=\"100\"></td><td><img src=https://www.polytec.com.au/img/products/960-960/white-magnetic.jpg width=\"100\"></td><td><img src=https://www.thespruceeats.com/thmb/qlT2neuIBeMYNR4w0K_GR-e2wZ4=/1885x1414/smart/filters:no_upscale()/Fruitsalad-GettyImages-811628388-5a0b1547482c5200372ddcd9.jpg width=\"100\"></td></tr></table>\n",
    "\n",
    "* By its nature, the treatment variable $D_i$ can only be observed once per case in individual $i$, i.e. those who received the treatment and those who did not, giving rise to the __counterfactual__ $\\color{red}{\\mathop{\\mathbb{E}}[Y_{0i}|D_i = 1]}$ — which is __unobservable__.\n",
    "\n",
    "\n",
    "* \"What would the outcome $Y_i$ be if an individual who did not receive treatment $D_i$ would have received it?\"\n",
    "\n",
    "\n",
    "* Randomization ensures that selection bias is zero: no underlying propensity/predisposition to exhibit a systematic response in some observable outcome after treatment $\\rightarrow$ conditional independence assumption (CIA, \"strict exogeneity\", \"ignorability condition\") holds\n",
    "\n",
    "    * Definition: \"conditioning on a set of covariates possible outcomes and treatment are independent\" (cannot predict treatment from the residuals)\n",
    "    * Hence: $y_i = \\beta D_i + \\epsilon_i$ $\\rightarrow$ $\\hat\\beta$ has a causal __interpretation__\n",
    "    * Special case of _Pearl's generalised graphical theory of causality_\n",
    "    \n",
    "Pearl's claim (in our words):\n",
    "\n",
    "> Even though the causal interpretation inherited from appropriate methods relying on well-known statistical properties may be justified, some objects, especially the \"counterfactual\", within this framework are subject to a lack of mathematical rigor, formalisation and identification.\n",
    "\n",
    "General note:\n",
    "\n",
    "- treatment may be continuous or discrete\n",
    "- $\\mathop{\\mathbb{E}}(\\mathord{\\cdot}) \\Leftrightarrow P(\\mathord{\\cdot})$ for discrete dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Linear) structural model\n",
    "\n",
    "### Graphical representation\n",
    "\n",
    "![meme](LM.png)\n",
    "\n",
    "$X$: hours studied<br>\n",
    "$Y$: points achieved\n",
    "\n",
    "- correlation (dashed lines)\n",
    "- causal relationship (solid line)\n",
    "- directionality (arrow)\n",
    "- missing edge between $u_X$ and $u_Y$: independence\n",
    "\n",
    "### Analytical representation\n",
    "\n",
    "\\begin{align*}\n",
    "f_{X}(u_{X}) &= X = u_X \\\\\n",
    "f_{Y}(X, u_Y) &= Y = \\beta X + u_Y\n",
    "\\end{align*}\n",
    "\n",
    "- ambiguous relationship (e.g. rearrange $X$ in terms of $Y$)\n",
    "    - possible remedy: IV estimation to inject directionality through exclusion assumptions and is operationalised through 2SLS which uncorrelates the error terms through the endogeneous variable\n",
    "\n",
    "\n",
    "- idea: combine graphical and analytical representations in a complementary way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The core\n",
    "\n",
    "\\begin{align*}\n",
    "Cov(X, u_Y) &= \\mathop{\\mathbb{E}}[X'\\epsilon] \\stackrel{!}{=} 0 \\quad \\text{in linear regression}\\\\\n",
    "\\\\\n",
    "Cov(X, u_Y) &= \\mathop{\\mathbb{E}}[X'\\epsilon] = 0 \\quad \\text{in structural equation modelling}\n",
    "\\end{align*}\n",
    "\n",
    "- in linear regression: an assumption __by construction__ in form of an optimality condition that comes out of the minimization of an L2 norm loss function\n",
    "\n",
    "Pearl (An Introduction to Causal Inference, 2010):\n",
    "\n",
    "> \"...parallels the celebrated “orthogonality” condition in linear models, $Cov(X,u_Y) = 0$, which has been used routinely, often thoughtlessly, to justify the estimation of structural coefficients by regression techniques.\"\n",
    "\n",
    "## Intermediate conclusion\n",
    "\n",
    "- counterfactual model and Pearl's graphical theory of causality are **fully compatible** with each other and are therefore **complementary and not rivalling** concepts\n",
    "\n",
    "\n",
    "- no specific functional form required to achieve identification and estimation\n",
    "\n",
    "\n",
    "- importance of collider (i.e. endogeneous) variables $\\rightarrow$ __back-door criterion__\n",
    "\n",
    "\n",
    "- irrelevance of the specific model: any model must, given a set of assumptions $A$, be able to identify the target quantity $Q$ [formally: $P(M_1) = P(M_2) \\Rightarrow Q(M_1) = Q(M_2)$]\n",
    "\n",
    "\n",
    "- domain knowledge, rigor notation and proper definition of the counterfactual:\n",
    "    - $Y_X(u) = Y_{M_{X}}(u)$ (\"value of $Y$ in unit $u$ had $X$ been $x$\")\n",
    "\n",
    "\n",
    "- use graphs to __explicitly__ encode all assumptions and __assist__ the researcher to __structure__ the process from problem to solution"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Py39 DoWhy",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
